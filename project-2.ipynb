{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "\n",
    "- Create project directory:\n",
    "```\n",
    "mkdir project-2-eliu390\n",
    "cd project-2-eliu390\n",
    "```\n",
    "\n",
    "\n",
    "- Download assessment data:\n",
    "```\n",
    "curl -L -o assessment-attempts-20180128-121051-nested.json https://goo.gl/ME6hjp\n",
    "```\n",
    "\n",
    "\n",
    "- Spin up Docker containers:\n",
    "```\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "\n",
    "- Container status check:\n",
    "```\n",
    "docker-compose logs -f kafka\n",
    "docker-compose ps\n",
    "```\n",
    "\n",
    "\n",
    "- Create Kafka topic \"assessments\":\n",
    "```\n",
    "docker-compose exec kafka kafka-topics --create --topic assessments --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181\n",
    "```\n",
    "\n",
    "\n",
    "- Kafka topic status check:\n",
    "```\n",
    "docker-compose exec kafka kafka-topics --describe --topic assessments --zookeeper zookeeper:32181\n",
    "```\n",
    "\n",
    "\n",
    "- Publish assessment data as Kafka event under \"assessments\" topic:\n",
    "```\n",
    "docker-compose exec mids bash -c \"cat /w205/project-2-eliu390/assessment-attempts-20180128-121051-nested.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t assessments\"\n",
    "```\n",
    "\n",
    "\n",
    "- Run Pyspark in Jupyter instance:\n",
    "```\n",
    "docker-compose exec spark env PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root --notebook-dir=/w205/' pyspark\n",
    "```\n",
    "\n",
    "\n",
    "- Create Firewall Rule under \"VPC Network\" for GCP AI Platform notebook:\n",
    "    - Allow IP range: 0.0.0.0/0\n",
    "    - Allow port: 8888\n",
    " \n",
    " \n",
    "- Navigate to Pyspark Jupyter instance URL\n",
    "    - Replace \"0.0.0.0\" with GCP notebook external IP address (found in GCP Compute Engine)\n",
    "    - Note: instance URL and GCP notebook IP address change upon restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, Transform, Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import explode, split\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, TimestampType, ArrayType\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assessments data was manually published using the command line as a Kafka event, under the topic \"assessments\". We now connect Spark to Kafka, subscribe to the \"assessments\" topic, and request all of the messages by setting a broad starting and ending offset for events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_assessments = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "  .option(\"subscribe\",\"assessments\") \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .option(\"endingOffsets\", \"latest\") \\\n",
    "  .load() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having Spark cache the raw data saves it in memory, which speeds up the next few exploratory operations on the data: printing the schema, showing the first entry, and casting the raw data (sent as binary by Kafka) as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_assessments.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_assessments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----------+---------+------+--------------------+-------------+\n",
      "| key|               value|      topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+-----------+---------+------+--------------------+-------------+\n",
      "|null|[7B 22 6B 65 65 6...|assessments|        0|     0|1969-12-31 23:59:...|            0|\n",
      "+----+--------------------+-----------+---------+------+--------------------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_assessments.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"keen_timestamp\"...|\n",
      "+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assessments = raw_assessments.select(raw_assessments.value.cast('string'))\n",
    "assessments.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='{\"keen_timestamp\":\"1516717442.735266\",\"max_attempts\":\"1.0\",\"started_at\":\"2018-01-23T14:23:19.082Z\",\"base_exam_id\":\"37f0a30a-7464-11e6-aa92-a8667f27e5dc\",\"user_exam_id\":\"6d4089e4-bde5-4a22-b65f-18bce9ab79c8\",\"sequences\":{\"questions\":[{\"user_incomplete\":true,\"user_correct\":false,\"options\":[{\"checked\":true,\"at\":\"2018-01-23T14:23:24.670Z\",\"id\":\"49c574b4-5c82-4ffd-9bd1-c3358faf850d\",\"submitted\":1,\"correct\":true},{\"checked\":true,\"at\":\"2018-01-23T14:23:25.914Z\",\"id\":\"f2528210-35c3-4320-acf3-9056567ea19f\",\"submitted\":1,\"correct\":true},{\"checked\":false,\"correct\":true,\"id\":\"d1bf026f-554f-4543-bdd2-54dcf105b826\"}],\"user_submitted\":true,\"id\":\"7a2ed6d3-f492-49b3-b8aa-d080a8aad986\",\"user_result\":\"missed_some\"},{\"user_incomplete\":false,\"user_correct\":false,\"options\":[{\"checked\":true,\"at\":\"2018-01-23T14:23:30.116Z\",\"id\":\"a35d0e80-8c49-415d-b8cb-c21a02627e2b\",\"submitted\":1},{\"checked\":false,\"correct\":true,\"id\":\"bccd6e2e-2cef-4c72-8bfa-317db0ac48bb\"},{\"checked\":true,\"at\":\"2018-01-23T14:23:41.791Z\",\"id\":\"7e0b639a-2ef8-4604-b7eb-5018bd81a91b\",\"submitted\":1,\"correct\":true}],\"user_submitted\":true,\"id\":\"bbed4358-999d-4462-9596-bad5173a6ecb\",\"user_result\":\"incorrect\"},{\"user_incomplete\":false,\"user_correct\":true,\"options\":[{\"checked\":false,\"at\":\"2018-01-23T14:23:52.510Z\",\"id\":\"a9333679-de9d-41ff-bb3d-b239d6b95732\"},{\"checked\":false,\"id\":\"85795acc-b4b1-4510-bd6e-41648a3553c9\"},{\"checked\":true,\"at\":\"2018-01-23T14:23:54.223Z\",\"id\":\"c185ecdb-48fb-4edb-ae4e-0204ac7a0909\",\"submitted\":1,\"correct\":true},{\"checked\":true,\"at\":\"2018-01-23T14:23:53.862Z\",\"id\":\"77a66c83-d001-45cd-9a5a-6bba8eb7389e\",\"submitted\":1,\"correct\":true}],\"user_submitted\":true,\"id\":\"e6ad8644-96b1-4617-b37b-a263dded202c\",\"user_result\":\"correct\"},{\"user_incomplete\":false,\"user_correct\":true,\"options\":[{\"checked\":false,\"id\":\"59b9fc4b-f239-4850-b1f9-912d1fd3ca13\"},{\"checked\":false,\"id\":\"2c29e8e8-d4a8-406e-9cdf-de28ec5890fe\"},{\"checked\":false,\"id\":\"62feee6e-9b76-4123-bd9e-c0b35126b1f1\"},{\"checked\":true,\"at\":\"2018-01-23T14:24:00.807Z\",\"id\":\"7f13df9c-fcbe-4424-914f-2206f106765c\",\"submitted\":1,\"correct\":true}],\"user_submitted\":true,\"id\":\"95194331-ac43-454e-83de-ea8913067055\",\"user_result\":\"correct\"}],\"attempt\":1,\"id\":\"5b28a462-7a3b-42e0-b508-09f3906d1703\",\"counts\":{\"incomplete\":1,\"submitted\":4,\"incorrect\":1,\"all_correct\":false,\"correct\":2,\"total\":4,\"unanswered\":0}},\"keen_created_at\":\"1516717442.735266\",\"certification\":\"false\",\"keen_id\":\"5a6745820eb8ab00016be1f1\",\"exam_name\":\"Normal Forms and All That Jazz Master Class\"}')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessments.collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By printing the entire contents of the first row, we see that each row represents one assessment. Thus, counting the number of rows gives the total number of assessments in the dataset: 3280."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessments.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After casting the raw data into strings, we can save and read the data in parquet format, using the \"overwrite\" operation to avoid errors and complications resulting from the data already having been previously written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "assessments.write.parquet(\"/tmp/assessments\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "|{\"keen_timestamp\"...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_assessments = spark.read.parquet('/tmp/assessments')\n",
    "read_assessments.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further convert the data from parquet format to RDD, the Spark equivalent of a DataFrame. This allows for some simple querying, but the nested data structures do not appear to suit this method well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+------------------+--------------------+\n",
      "|json.max_attempts|      json.sequences|json.certification|      json.exam_name|\n",
      "+-----------------+--------------------+------------------+--------------------+\n",
      "|              1.0|[1,[false,2,1,1,4...|             false|Normal Forms and ...|\n",
      "|              1.0|[1,[false,1,2,1,4...|             false|Normal Forms and ...|\n",
      "|              1.0|[1,[false,3,0,1,4...|             false|The Principles of...|\n",
      "|              1.0|[1,[false,2,2,0,4...|             false|The Principles of...|\n",
      "|              1.0|[1,[false,3,0,1,4...|             false|Introduction to B...|\n",
      "|              1.0|[1,[true,5,0,0,5,...|             false|        Learning Git|\n",
      "|              1.0|[1,[true,1,0,0,1,...|             false|Git Fundamentals ...|\n",
      "|              1.0|[1,[true,5,0,0,5,...|             false|Introduction to P...|\n",
      "|              1.0|[1,[true,4,0,0,4,...|             false|Intermediate Pyth...|\n",
      "|              1.0|[1,[false,0,1,0,1...|             false|Introduction to P...|\n",
      "|              1.0|[1,[false,3,1,0,4...|             false|A Practical Intro...|\n",
      "|              1.0|[1,[true,1,0,0,1,...|             false|Git Fundamentals ...|\n",
      "|              1.0|[1,[false,4,1,1,6...|             false|Introduction to M...|\n",
      "|              1.0|[1,[false,4,0,2,6...|             false|   Python Epiphanies|\n",
      "|              1.0|[1,[false,4,1,0,5...|             false|Introduction to P...|\n",
      "|              1.0|[1,[false,3,0,1,4...|             false|Python Data Struc...|\n",
      "|              1.0|[1,[false,3,0,0,3...|             false|Python Data Struc...|\n",
      "|              1.0|[1,[true,4,0,0,4,...|             false|Working with Algo...|\n",
      "|              1.0|[1,[false,2,0,0,2...|             false|Learning iPython ...|\n",
      "|              1.0|[1,[true,6,0,0,6,...|             false|   Python Epiphanies|\n",
      "+-----------------+--------------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform to DataFrame\n",
    "from pyspark.sql.functions import from_json, col\n",
    "json_schema = spark.read.json(read_assessments.rdd.map(lambda row: row.value)).schema\n",
    "read_assessments = read_assessments.withColumn('json', from_json(col('value'), json_schema))\n",
    "read_assessments.select(\n",
    "    read_assessments.json.max_attempts,\n",
    "    read_assessments.json.sequences,\n",
    "    read_assessments.json.certification,\n",
    "    read_assessments.json.exam_name\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually define the schema for each assessment. Many of the fields will likely be unimportant, but we do not omit any here in case they do become useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "assessments_schema = StructType([\n",
    "    StructField('keen_timestamp', StringType(), True),\n",
    "    StructField('max_attempts', StringType(), True),\n",
    "    StructField('started_at', StringType(), True),\n",
    "    StructField('base_exam_id', StringType(), True),\n",
    "    StructField('user_exam_id', StringType(), True),\n",
    "    StructField('keen_created_at', StringType(), True),\n",
    "    StructField('certification', StringType(), True),\n",
    "    StructField('keen_id', StringType(), True),\n",
    "    StructField('exam_name', StringType(), True),\n",
    "    StructField('sequences', StructType([\n",
    "        StructField('attempt', StringType(), True),\n",
    "        StructField('id', StringType(), True),\n",
    "        StructField('questions', ArrayType(StructType([\n",
    "            StructField('user_incomplete', BooleanType(), True),\n",
    "            StructField('user_correct', BooleanType(), True),\n",
    "            StructField('user_submitted', StringType(), True),\n",
    "            StructField('id', StringType(), True),\n",
    "            StructField('user_result', StringType(), True),\n",
    "            StructField('options', ArrayType(StructType([\n",
    "                StructField('checked', BooleanType(), True),\n",
    "                StructField('at', StringType(), True),\n",
    "                StructField('id', StringType(), True),\n",
    "                StructField('submitted', StringType(), True),\n",
    "                StructField('correct', BooleanType(), True)\n",
    "            ]), False), True)\n",
    "        ]), False)),\n",
    "        StructField('counts', StructType([\n",
    "            StructField('incomplete', IntegerType(), True),\n",
    "            StructField('submitted', IntegerType(), True),\n",
    "            StructField('incorrect', IntegerType(), True),\n",
    "            StructField('all_correct', BooleanType(), True),\n",
    "            StructField('correct', IntegerType(), True),\n",
    "            StructField('total', IntegerType(), True),\n",
    "            StructField('unanswered', IntegerType(), True)\n",
    "        ]))\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the schema defined above, we can write the assessments data as an RDD with the correct structure. We then verify the schema by printing the schema and making simple queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "struct_assessments = assessments.rdd.map(lambda x: json.loads(x.value)).toDF(schema=assessments_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- keen_timestamp: string (nullable = true)\n",
      " |-- max_attempts: string (nullable = true)\n",
      " |-- started_at: string (nullable = true)\n",
      " |-- base_exam_id: string (nullable = true)\n",
      " |-- user_exam_id: string (nullable = true)\n",
      " |-- keen_created_at: string (nullable = true)\n",
      " |-- certification: string (nullable = true)\n",
      " |-- keen_id: string (nullable = true)\n",
      " |-- exam_name: string (nullable = true)\n",
      " |-- sequences: struct (nullable = true)\n",
      " |    |-- attempt: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- questions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = false)\n",
      " |    |    |    |-- user_incomplete: boolean (nullable = true)\n",
      " |    |    |    |-- user_correct: boolean (nullable = true)\n",
      " |    |    |    |-- user_submitted: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- user_result: string (nullable = true)\n",
      " |    |    |    |-- options: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = false)\n",
      " |    |    |    |    |    |-- checked: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- at: string (nullable = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- submitted: string (nullable = true)\n",
      " |    |    |    |    |    |-- correct: boolean (nullable = true)\n",
      " |    |-- counts: struct (nullable = true)\n",
      " |    |    |-- incomplete: integer (nullable = true)\n",
      " |    |    |-- submitted: integer (nullable = true)\n",
      " |    |    |-- incorrect: integer (nullable = true)\n",
      " |    |    |-- all_correct: boolean (nullable = true)\n",
      " |    |    |-- correct: integer (nullable = true)\n",
      " |    |    |-- total: integer (nullable = true)\n",
      " |    |    |-- unanswered: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "struct_assessments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Normal Forms and All That Jazz Master Class'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_assessments.take(1)[0]['exam_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_assessments.take(1)[0]['sequences']['counts']['all_correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_assessments.take(1)[0]['sequences']['questions'][0]['options'][0]['checked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the correctly-structured RDD to a relational table, which allows for SQL queries. We test this with a few simple example queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "struct_assessments.registerTempTable('assessments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           exam_name|\n",
      "+--------------------+\n",
      "|Normal Forms and ...|\n",
      "|Normal Forms and ...|\n",
      "|The Principles of...|\n",
      "|The Principles of...|\n",
      "|Introduction to B...|\n",
      "|        Learning Git|\n",
      "|Git Fundamentals ...|\n",
      "|Introduction to P...|\n",
      "|Intermediate Pyth...|\n",
      "|Introduction to P...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT exam_name FROM assessments\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|   exam_name|\n",
      "+------------+\n",
      "|Learning Git|\n",
      "+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT \\\n",
    "exam_name \\\n",
    "FROM assessments \\\n",
    "WHERE sequences.counts.all_correct = True\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Business Questions with Data Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many different exams are present in this dataset?**\n",
    "\n",
    "By counting the number of unique exam IDs, we find that there are 107 unique exam IDs represented in this dataset. This likely corresponds to 107 unique exams, each with multiple attempts by different students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|count(DISTINCT base_exam_id)|\n",
      "+----------------------------+\n",
      "|                         107|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(DISTINCT base_exam_id) FROM assessments\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do any exams have more than one occurrence?**\n",
    "\n",
    "By counting the number of unique exam IDs per exam name, we find that only a few exams are represented multiple times in the dataset, while most exams occur only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------+---------+\n",
      "|exam_name                                                              |num_exams|\n",
      "+-----------------------------------------------------------------------+---------+\n",
      "|Introduction to Python                                                 |2        |\n",
      "|Great Bash                                                             |2        |\n",
      "|Architectural Considerations for Hadoop Applications                   |2        |\n",
      "|Being a Better Introvert                                               |2        |\n",
      "|Learning Data Modeling                                                 |1        |\n",
      "|Networking for People Who Hate Networking                              |1        |\n",
      "|Introduction to Java 8                                                 |1        |\n",
      "|Learning Apache Hadoop                                                 |1        |\n",
      "|Learning Spring Programming                                            |1        |\n",
      "|Learning iPython Notebook                                              |1        |\n",
      "|Mastering Python - Networking and Security                             |1        |\n",
      "|Learning C# Best Practices                                             |1        |\n",
      "|Introduction to Architecting Amazon Web Services                       |1        |\n",
      "|A Practical Introduction to React.js                                   |1        |\n",
      "|I'm a Software Architect, Now What?                                    |1        |\n",
      "|Introduction to Big Data                                               |1        |\n",
      "|View Updating                                                          |1        |\n",
      "|Learning to Visualize Data with D3.js                                  |1        |\n",
      "|Intermediate C# Programming                                            |1        |\n",
      "|Starting a Grails 3 Project                                            |1        |\n",
      "|Introduction to Apache Spark                                           |1        |\n",
      "|JavaScript Templating                                                  |1        |\n",
      "|Learning C# Design Patterns                                            |1        |\n",
      "|Data Visualization in R with ggplot2                                   |1        |\n",
      "|Modeling for Software Architects                                       |1        |\n",
      "|Mastering Advanced Git                                                 |1        |\n",
      "|Learning Apache Maven                                                  |1        |\n",
      "|Learning DNS                                                           |1        |\n",
      "|An Introduction to Set Theory                                          |1        |\n",
      "|Event-Driven Microservices                                             |1        |\n",
      "|Refactor a Monolithic Architecture into Microservices                  |1        |\n",
      "|Reproducible Research and Reports with R Markdown                      |1        |\n",
      "|Understanding the Grails 3 Domain Model                                |1        |\n",
      "|Learning Git                                                           |1        |\n",
      "|Introduction to Hadoop YARN                                            |1        |\n",
      "|Learning Linux System Administration                                   |1        |\n",
      "|Service Based Architectures                                            |1        |\n",
      "|Python Data Structures                                                 |1        |\n",
      "|Amazon Web Services - Simple Storage Service                           |1        |\n",
      "|Introduction to Apache Kafka                                           |1        |\n",
      "|Offline Web                                                            |1        |\n",
      "|SQL: Beyond the Basics                                                 |1        |\n",
      "|Arduino Prototyping Techniques                                         |1        |\n",
      "|Amazon Web Services - Virtual Private Cloud                            |1        |\n",
      "|Nullology                                                              |1        |\n",
      "|Example Exam For Development and Testing oh yeahsdf                    |1        |\n",
      "|Building Web Services with Java                                        |1        |\n",
      "|Introduction to Apache Hive                                            |1        |\n",
      "|Cloud Native Architecture Fundamentals                                 |1        |\n",
      "|Arduino Inputs                                                         |1        |\n",
      "|Learning Linux Security                                                |1        |\n",
      "|Arduino Prototyping Basics                                             |1        |\n",
      "|Introduction to Machine Learning                                       |1        |\n",
      "|Learning Java EE 7                                                     |1        |\n",
      "|Nulls, Three-valued Logic and Missing Information                      |1        |\n",
      "|Mastering Web Views                                                    |1        |\n",
      "|An Introduction to d3.js: From Scattered to Scatterplot                |1        |\n",
      "|TCP/IP                                                                 |1        |\n",
      "|Mastering Git                                                          |1        |\n",
      "|Introduction to Data Science with R                                    |1        |\n",
      "|Learning to Program with R                                             |1        |\n",
      "|Using Storytelling to Effectively Communicate Data                     |1        |\n",
      "|Design Patterns in Java                                                |1        |\n",
      "|Learning Apache Cassandra                                              |1        |\n",
      "|The Principles of Microservices                                        |1        |\n",
      "|Hibernate and JPA Fundamentals                                         |1        |\n",
      "|Learning Data Structures and Algorithms                                |1        |\n",
      "|Getting Ready for Angular 2                                            |1        |\n",
      "|Beginning C# Programming                                               |1        |\n",
      "|Software Architecture Fundamentals Understanding the Basics            |1        |\n",
      "|The Closed World Assumption                                            |1        |\n",
      "|Hadoop Fundamentals for Data Scientists                                |1        |\n",
      "|Web & Native Working Together                                          |1        |\n",
      "|Learning SQL                                                           |1        |\n",
      "|Practical Java Programming                                             |1        |\n",
      "|Using R for Big Data with Spark                                        |1        |\n",
      "|JavaScript: The Good Parts Master Class with Douglas Crockford         |1        |\n",
      "|Intermediate Python Programming                                        |1        |\n",
      "|Collaborating with Git                                                 |1        |\n",
      "|Introduction to Time Series with Team Apache                           |1        |\n",
      "|Introduction to Modern Client-Side Programming                         |1        |\n",
      "|Learning Eclipse                                                       |1        |\n",
      "|Working with Algorithms in Python                                      |1        |\n",
      "|Using Web Components                                                   |1        |\n",
      "|Git Fundamentals for Web Developers                                    |1        |\n",
      "|Relational Theory for Computer Professionals                           |1        |\n",
      "|Normal Forms and All That Jazz Master Class                            |1        |\n",
      "|What's New in JavaScript                                               |1        |\n",
      "|Introduction to Modern Front-End Development                           |1        |\n",
      "|Software Architecture Fundamentals Beyond The Basics                   |1        |\n",
      "|Learning SQL for Oracle                                                |1        |\n",
      "|Data Science with Microsoft Azure and R                                |1        |\n",
      "|Native Web Apps for Android                                            |1        |\n",
      "|Introduction to Shiny                                                  |1        |\n",
      "|Python Epiphanies                                                      |1        |\n",
      "|Client-Side Data Storage for Web Developers                            |1        |\n",
      "|Introduction to Amazon Web Services (AWS) - EC2 Deployment Fundamentals|1        |\n",
      "|Advanced Machine Learning                                              |1        |\n",
      "|Cloud Computing With AWS                                               |1        |\n",
      "|Operating Red Hat Enterprise Linux Servers                             |1        |\n",
      "|HTML5 The Basics                                                       |1        |\n",
      "|Expert Data Wrangling with R                                           |1        |\n",
      "|Beginning Programming with JavaScript                                  |1        |\n",
      "+-----------------------------------------------------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT \\\n",
    "exam_name, \\\n",
    "COUNT(DISTINCT base_exam_id) AS num_exams \\\n",
    "FROM assessments \\\n",
    "GROUP BY exam_name \\\n",
    "ORDER BY num_exams DESC\").show(107, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When defining the schema, an error occurred if the \"certification\" field was mapped to a BooleanType. Apparently, the \"certification\" field apparently contains only \"null\" and \"false\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|certification|count(1)|\n",
      "+-------------+--------+\n",
      "|null         |132     |\n",
      "|false        |3148    |\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT \\\n",
    "certification, \\\n",
    "COUNT(*) \\\n",
    "FROM assessments \\\n",
    "GROUP BY certification\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What was the most popular class?**\n",
    "\n",
    "We group assessments by exam ID and exam name, in order to avoid double-counting the exams that appear twice in the dataset. Assuming that the number of exams for a class exactly equals the number of students taking the class, the most popular class was \"Learning Git\", with 394 students.\n",
    "\n",
    "In the rest of this report, we explore the \"Learning Git\" assessments with more in-depth queries. However, note that these are examples that are applicable to all exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------------------------------------------+------------------------------------+\n",
      "|num|exam_name                                                              |base_exam_id                        |\n",
      "+---+-----------------------------------------------------------------------+------------------------------------+\n",
      "|394|Learning Git                                                           |8b4488de-43a5-4ffa-bf82-af1e19ee1b64|\n",
      "|158|Introduction to Java 8                                                 |41858ac3-1394-451b-bf7c-c10f52034a9a|\n",
      "|158|Intermediate Python Programming                                        |1a233da8-e6e5-48a6-8c3c-806e312cce12|\n",
      "|128|Learning to Program with R                                             |b114e4a4-a192-4dff-a5cd-8e7782bb1623|\n",
      "|122|Introduction to Python                                                 |7e2e0b53-a7ba-458d-8bc6-356f8dea8815|\n",
      "|119|Introduction to Machine Learning                                       |c464bf80-6bca-11e6-a9a9-a8667f27e5dc|\n",
      "|109|Software Architecture Fundamentals Understanding the Basics            |ad6ad93e-0d28-47e3-b655-1cf8852b254e|\n",
      "|95 |Beginning C# Programming                                               |1afec2b2-6178-4ce7-8154-5f0c9a3959c9|\n",
      "|85 |Learning Eclipse                                                       |f3f88f87-7151-11e6-ba4a-a4d18ccf3cb4|\n",
      "|80 |Learning Apache Maven                                                  |846364d4-7153-11e6-9ab8-a4d18ccf3cb4|\n",
      "|79 |Beginning Programming with JavaScript                                  |9547a6eb-715e-11e6-9b72-a4d18ccf3cb4|\n",
      "|77 |Mastering Git                                                          |5d0f436c-ec7b-4269-95e2-825946a026ee|\n",
      "|75 |Introduction to Big Data                                               |6442707e-7488-11e6-831b-a8667f27e5dc|\n",
      "|67 |Advanced Machine Learning                                              |e824836a-3835-4e79-b070-ae6d0da89b3e|\n",
      "|59 |Learning Linux System Administration                                   |a62e5d35-75e9-11e6-8197-9801a7c3b233|\n",
      "|58 |JavaScript: The Good Parts Master Class with Douglas Crockford         |77ba773a-715e-11e6-899f-a4d18ccf3cb4|\n",
      "|57 |Learning SQL                                                           |a3cf5a0f-6bd8-11e6-8d83-a8667f27e5dc|\n",
      "|53 |Practical Java Programming                                             |786af9ee-7153-11e6-b53e-a4d18ccf3cb4|\n",
      "|52 |HTML5 The Basics                                                       |8aaa9a07-1e0a-47b0-9146-f3310e018e61|\n",
      "|51 |Python Epiphanies                                                      |a7a65ec6-77dc-480d-9926-dd0012677829|\n",
      "|48 |Software Architecture Fundamentals Beyond The Basics                   |ca00f150-41b3-41c0-8d64-372c631a8244|\n",
      "|43 |Introduction to Data Science with R                                    |7b398106-8b73-4e73-b133-edff27cd6904|\n",
      "|43 |Intermediate C# Programming                                            |94b741b2-fc67-4db4-adc2-aafae130848f|\n",
      "|40 |Introduction to Python                                                 |747d6bf1-4c14-438f-b85f-e1111ccc4b15|\n",
      "|40 |Learning DNS                                                           |b2264d14-7699-11e6-b275-9801a7c3b233|\n",
      "|35 |Expert Data Wrangling with R                                           |f957412c-b316-4fa1-8af4-cfcdb5ad1e63|\n",
      "|35 |Learning C# Best Practices                                             |56c8b891-0d34-4a87-b2aa-9de816823784|\n",
      "|34 |Mastering Advanced Git                                                 |4b546345-b897-4184-af39-21eb9d6c0321|\n",
      "|33 |An Introduction to d3.js: From Scattered to Scatterplot                |9ff51f14-7525-11e6-a5b2-a4d18ccf3cb4|\n",
      "|31 |Data Visualization in R with ggplot2                                   |5a1a0072-47c5-4789-abf1-a38c7d75716d|\n",
      "|29 |Cloud Native Architecture Fundamentals                                 |2cac6396-6c41-11e7-a76e-6b377f1287a6|\n",
      "|29 |Python Data Structures                                                 |e5602ceb-6f0d-11e6-8aff-9801a7c3b233|\n",
      "|28 |Introduction to Time Series with Team Apache                           |6672aad3-934b-4265-9417-15e8e903a48d|\n",
      "|28 |Git Fundamentals for Web Developers                                    |e1f07fac-5566-4fdd-95e0-b6aa06fd5b50|\n",
      "|27 |Introduction to Shiny                                                  |9bcbb38f-c017-498a-976d-9a3bb889f79b|\n",
      "|27 |Learning Linux Security                                                |76f39b28-76be-11e6-ae8a-9801a7c3b233|\n",
      "|25 |Learning Java EE 7                                                     |05a30b30-0465-42ef-b5d7-598e61840025|\n",
      "|25 |Mastering Python - Networking and Security                             |dd9e3175-45a4-4913-b1d2-1f64e183fc53|\n",
      "|24 |Using R for Big Data with Spark                                        |526908f1-9c67-4ab4-9882-a87973374a3b|\n",
      "|23 |Learning C# Design Patterns                                            |a8dedd1d-0f67-4f4c-a41e-763dbb764493|\n",
      "|21 |JavaScript Templating                                                  |8adc4a4f-715e-11e6-a6b8-a4d18ccf3cb4|\n",
      "|21 |Reproducible Research and Reports with R Markdown                      |be722e22-6b18-4c4b-9547-6fe75c218f99|\n",
      "|21 |TCP/IP                                                                 |8fcb41f8-76ac-11e6-99b2-9801a7c3b233|\n",
      "|17 |Learning iPython Notebook                                              |76a682de-6f0c-11e6-b36d-9801a7c3b233|\n",
      "|17 |Cloud Computing With AWS                                               |dac38d07-748d-11e6-afe6-a4d18ccf3cb4|\n",
      "|17 |Refactor a Monolithic Architecture into Microservices                  |95c09e8f-6292-4471-b939-5ba87c3c62ff|\n",
      "|16 |Learning Apache Hadoop                                                 |417d1748-76ab-11e6-ae96-a8667f27e5dc|\n",
      "|15 |I'm a Software Architect, Now What?                                    |f80366d9-db60-41c3-a1c4-6c7789b478f8|\n",
      "|15 |Design Patterns in Java                                                |500c5332-2ab4-4f65-9cd9-80420c2d4012|\n",
      "|15 |Networking for People Who Hate Networking                              |8e23138f-8a50-4f69-ad87-6b46c89a2153|\n",
      "|15 |Relational Theory for Computer Professionals                           |9fd6c9e2-709f-11e6-8871-a8667f27e5dc|\n",
      "|14 |Introduction to Architecting Amazon Web Services                       |0161dadc-748e-11e6-bcd0-a4d18ccf3cb4|\n",
      "|14 |Working with Algorithms in Python                                      |f432e2e3-7e3a-4a78-b408-49cab5d1fbeb|\n",
      "|13 |Introduction to Modern Client-Side Programming                         |30165eb8-4429-433d-90a8-affe7c780766|\n",
      "|13 |Introduction to Apache Kafka                                           |d944b130-46a0-455b-b721-92de373afd71|\n",
      "|13 |Offline Web                                                            |f67fc173-7460-11e6-8f77-a4d18ccf3cb4|\n",
      "|13 |Learning Data Structures and Algorithms                                |0e556c3d-199e-44e6-9fae-0e8b54b6444f|\n",
      "|12 |Amazon Web Services - Simple Storage Service                           |f0633ed7-748d-11e6-853c-a4d18ccf3cb4|\n",
      "|12 |Learning Apache Cassandra                                              |dff2ec2e-79f6-11e6-a4fc-a8667f27e5dc|\n",
      "|11 |Amazon Web Services - Virtual Private Cloud                            |e5fee01e-748d-11e6-9470-a4d18ccf3cb4|\n",
      "|11 |SQL: Beyond the Basics                                                 |ee5b6f14-709d-11e6-b75b-a8667f27e5dc|\n",
      "|11 |Learning SQL for Oracle                                                |cc2dac54-709b-11e6-8b35-a8667f27e5dc|\n",
      "|11 |The Principles of Microservices                                        |4beeac16-bb83-4d58-83e4-26cdc38f0481|\n",
      "|10 |Event-Driven Microservices                                             |0678c2d4-f70d-4aa1-ae3a-59b3bb8f5725|\n",
      "|10 |Arduino Prototyping Basics                                             |1ec46a4c-c038-4bd1-b730-09557635ecbf|\n",
      "|9  |Learning Data Modeling                                                 |479f39cc-70a9-11e6-a73e-a8667f27e5dc|\n",
      "|9  |A Practical Introduction to React.js                                   |4cdf9b5f-fdb7-4a4f-aaf3-51ec08dedecb|\n",
      "|9  |Introduction to Apache Spark                                           |d46f46ea-de56-4fd3-a578-9642ff4c3665|\n",
      "|8  |Great Bash                                                             |0fed9e6e-6438-4644-a59d-e581e844d5e2|\n",
      "|8  |Web & Native Working Together                                          |98a4b6fd-7460-11e6-b6c2-a4d18ccf3cb4|\n",
      "|8  |Introduction to Hadoop YARN                                            |1d2a2d14-7484-11e6-9444-a8667f27e5dc|\n",
      "|8  |Nullology                                                              |4ea9383e-745d-11e6-94c4-a8667f27e5dc|\n",
      "|8  |Being a Better Introvert                                               |ee725ec8-d26b-4263-b8aa-c76592d1edf4|\n",
      "|8  |Arduino Inputs                                                         |beec531b-e87e-4ab7-ab2a-02c03dff3676|\n",
      "|7  |Data Science with Microsoft Azure and R                                |4df97d5f-4f98-4d1e-9270-9a0bbd9bb60e|\n",
      "|7  |Normal Forms and All That Jazz Master Class                            |37f0a30a-7464-11e6-aa92-a8667f27e5dc|\n",
      "|7  |Introduction to Apache Hive                                            |5ff1ceda-7485-11e6-ba39-a8667f27e5dc|\n",
      "|7  |Architectural Considerations for Hadoop Applications                   |39365c35-f99a-4b59-8ba9-c511350f090a|\n",
      "|6  |Collaborating with Git                                                 |615d8873-5947-48c0-bc4e-01069a0b2d20|\n",
      "|6  |Hadoop Fundamentals for Data Scientists                                |b4da3808-7474-11e6-a15c-a8667f27e5dc|\n",
      "|6  |Great Bash                                                             |16c98e57-76bc-11e6-a7d7-9801a7c3b233|\n",
      "|6  |Introduction to Amazon Web Services (AWS) - EC2 Deployment Fundamentals|f9de34a3-748d-11e6-a58a-a4d18ccf3cb4|\n",
      "|6  |Introduction to Modern Front-End Development                           |87b4b3f9-3a86-435e-8360-25379c6978ca|\n",
      "|5  |Example Exam For Development and Testing oh yeahsdf                    |example-id                          |\n",
      "|5  |An Introduction to Set Theory                                          |e700d410-7460-11e6-8afe-a8667f27e5dc|\n",
      "|5  |Modeling for Software Architects                                       |f83fae20-8d97-40d7-b4d5-23e5725d2d4d|\n",
      "|5  |Starting a Grails 3 Project                                            |b0011798-80dd-4cb2-988c-23239e9d52c2|\n",
      "|4  |Using Storytelling to Effectively Communicate Data                     |b71d9e1e-7525-11e6-927c-a4d18ccf3cb4|\n",
      "|4  |View Updating                                                          |44d5ca66-7462-11e6-9d9f-a8667f27e5dc|\n",
      "|3  |Service Based Architectures                                            |a2be982d-5391-4f19-af0f-1fb47a259c6c|\n",
      "|3  |Building Web Services with Java                                        |addea30d-949c-4c30-a562-fc231b1c3f7c|\n",
      "|3  |Getting Ready for Angular 2                                            |2000fbc1-32b8-41cd-b794-da01b1aedae7|\n",
      "|3  |Using Web Components                                                   |30fd83f9-4937-4a00-bcf3-42e495fecd55|\n",
      "|3  |Mastering Web Views                                                    |ffc5c454-7460-11e6-bea1-a4d18ccf3cb4|\n",
      "|3  |Architectural Considerations for Hadoop Applications                   |b205eb22-7b95-11e6-84f8-a8667f27e5dc|\n",
      "|2  |Arduino Prototyping Techniques                                         |c2b52796-0dad-4e08-a40f-b2081dd965db|\n",
      "|2  |Learning Spring Programming                                            |3472e558-8f0f-4be4-a57d-30edfbd181de|\n",
      "|2  |Understanding the Grails 3 Domain Model                                |1daab041-cdd9-4287-b6b8-ed55b32153e6|\n",
      "|2  |Hibernate and JPA Fundamentals                                         |0953542c-e6b4-46cf-a0c2-958a914c2715|\n",
      "|2  |Being a Better Introvert                                               |392651a1-e62f-4e72-b7dd-88df2253bc49|\n",
      "|2  |What's New in JavaScript                                               |e9b58c58-bf2e-4bde-be81-52fb02ebc892|\n",
      "|2  |The Closed World Assumption                                            |f224b886-745e-11e6-8f07-a8667f27e5dc|\n",
      "|2  |Client-Side Data Storage for Web Developers                            |d56d0878-1b66-45a9-a743-d280e8b4a791|\n",
      "|1  |Nulls, Three-valued Logic and Missing Information                      |b0117330-7461-11e6-a8f1-a8667f27e5dc|\n",
      "|1  |Native Web Apps for Android                                            |13013db3-7461-11e6-8054-a4d18ccf3cb4|\n",
      "|1  |Learning to Visualize Data with D3.js                                  |3528cd24-01a4-47e8-b2cf-c4b54e143284|\n",
      "|1  |Operating Red Hat Enterprise Linux Servers                             |3aa9edb7-6031-41f9-b07e-2380ae6b857a|\n",
      "+---+-----------------------------------------------------------------------+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT \\\n",
    "COUNT(*) AS num, \\\n",
    "exam_name, \\\n",
    "base_exam_id \\\n",
    "FROM assessments \\\n",
    "GROUP BY base_exam_id, exam_name \\\n",
    "ORDER BY num DESC\").show(107, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many students got every question correct on the \"Learning Git\" exam?**\n",
    "\n",
    "Each assessment contains a record of whether the student got all questions correct. We find that 130 students got every question correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|num_students|\n",
      "+------------+\n",
      "|         130|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT \\\n",
    "COUNT(*) AS num_students \\\n",
    "FROM assessments \\\n",
    "WHERE sequences.counts.all_correct = True \\\n",
    "AND exam_name = 'Learning Git'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What was the average score on the \"Learning Git\" exam?**\n",
    "\n",
    "Each assessment contains a record of the number of questions the student answered correctly and the total number of questions. Summing these over all students gives an average score of 1332/1970 = 67.6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|num_correct_answers|num_total_answers|\n",
      "+-------------------+-----------------+\n",
      "|               1332|             1970|\n",
      "+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT \\\n",
    "SUM(sequences.counts.correct) AS num_correct_answers, \\\n",
    "SUM(sequences.counts.total) AS num_total_answers \\\n",
    "FROM assessments \\\n",
    "WHERE exam_name = 'Learning Git'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What were the easiest and hardest questions on the \"Learning Git\" exam?**\n",
    "\n",
    "We assume the difficulty of a question is related to the proportion of students who got it wrong. The fewer students got a question wrong, the easier the question was, and vice versa. By counting the number of assessments with correct answers for each question, we find that questions 1 and 2 were the easiest, with 270/394 = 68.5% of students answering correctly, while question 3 was the hardest, with 261/394 = 66.2% of students answering correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+\n",
      "|q1_correct|q2_correct|q3_correct|q4_correct|q5_correct|\n",
      "+----------+----------+----------+----------+----------+\n",
      "|       270|       270|       261|       264|       267|\n",
      "+----------+----------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT \\\n",
    "SUM(CASE sequences.questions[0].user_correct WHEN True THEN 1 ELSE 0 END) AS q1_correct, \\\n",
    "SUM(CASE sequences.questions[1].user_correct WHEN True THEN 1 ELSE 0 END) AS q2_correct, \\\n",
    "SUM(CASE sequences.questions[2].user_correct WHEN True THEN 1 ELSE 0 END) AS q3_correct, \\\n",
    "SUM(CASE sequences.questions[3].user_correct WHEN True THEN 1 ELSE 0 END) AS q4_correct, \\\n",
    "SUM(CASE sequences.questions[4].user_correct WHEN True THEN 1 ELSE 0 END) AS q5_correct \\\n",
    "FROM assessments \\\n",
    "WHERE exam_name = 'Learning Git'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On question 3 of the \"Learning Git\" exam, how many answer choices were there?**\n",
    "\n",
    "There were 4 answer choices for question 3 of the \"Learning Git\" exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|num_choices|\n",
      "+-----------+\n",
      "|          4|\n",
      "+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT \\\n",
    "size(sequences.questions[2].options) AS num_choices \\\n",
    "FROM assessments \\\n",
    "WHERE exam_name = 'Learning Git'\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On question 3 of the \"Learning Git\" exam, which incorrect answer choice was chosen most frequently?**\n",
    "\n",
    "Apparently, within each question the correct answer choice is randomized. Each answer choice only contains an id, and there is no way to determine the contents of each answer choice from this data. However, we can still ask a different question:\n",
    "\n",
    "**On question 3 of the \"Learning Git\" exam, how often was each answer choice the correct one?**\n",
    "\n",
    "Option 2 was the correct choice substantially more often than the others. With perfect randomization, we should expect each answer choice to be the correct one about 394/4 = 99 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+------------+\n",
      "|opt1_correct|opt2_correct|opt3_correct|opt4_correct|\n",
      "+------------+------------+------------+------------+\n",
      "|         101|         121|          91|          81|\n",
      "+------------+------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT \\\n",
    "SUM(CASE sequences.questions[2].options[0].correct WHEN True THEN 1 ELSE 0 END) AS opt1_correct, \\\n",
    "SUM(CASE sequences.questions[2].options[1].correct WHEN True THEN 1 ELSE 0 END) AS opt2_correct, \\\n",
    "SUM(CASE sequences.questions[2].options[2].correct WHEN True THEN 1 ELSE 0 END) AS opt3_correct, \\\n",
    "SUM(CASE sequences.questions[2].options[3].correct WHEN True THEN 1 ELSE 0 END) AS opt4_correct \\\n",
    "FROM assessments \\\n",
    "WHERE exam_name = 'Learning Git'\").show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
